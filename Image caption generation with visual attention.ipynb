{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('flickr8k.zip', \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8091\n",
      "['1000268201_693b08cb0e.jpg,A child in a pink dress is climbing up a set of stairs in an entry way .\\n'\n",
      " '1000268201_693b08cb0e.jpg,A girl going into a wooden building .\\n'\n",
      " '1000268201_693b08cb0e.jpg,A little girl climbing into a wooden playhouse .\\n'\n",
      " '1000268201_693b08cb0e.jpg,A little girl climbing the stairs to her playhouse .\\n'\n",
      " '1000268201_693b08cb0e.jpg,A little girl in a pink dress going into a wooden cabin .\\n']\n"
     ]
    }
   ],
   "source": [
    "output_file = open('captions.txt',mode='r')\n",
    "lines = output_file.readlines()\n",
    "lines.pop(0)\n",
    "lines = np.asarray(lines)\n",
    "l = len(lines)\n",
    "l = int(l/5)\n",
    "print(l)\n",
    "lines.shape = (l,5)\n",
    "print(lines[0])\n",
    "X = np.empty((l,224,224,3))\n",
    "Y = np.empty((l,35,5))\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in glob.glob('./Images/*'):\n",
    "  image = Image.open(images)\n",
    "  x_center = image.size[0]\n",
    "  y_center = image.size[1]\n",
    "  left = x_center - 112\n",
    "  right = x_center + 112\n",
    "  upper = y_center - 112\n",
    "  lower = y_center + 112\n",
    "  image = image.crop((left,upper,right,lower))\n",
    "  data = asarray(image)\n",
    "  X[i, :, :, :] = data\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 35 # max length our sentence will be\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, sent_train, sent_test = train_test_split(X, lines, test_size=0.1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091, 5) (35455,)\n"
     ]
    }
   ],
   "source": [
    "flatten_sent_train = sent_train.flatten()\n",
    "l_train = sent_train.shape[0]\n",
    "print(sent_train.shape,flatten_sent_train.shape)\n",
    "text_vectorizer.adapt(flatten_sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3343197133_9256848fa9.jpg,A biker gets high in the air against a skyline .\\n'\n",
      "  '3343197133_9256848fa9.jpg,A boy wearing a white helmet jumping on his bike .\\n'\n",
      "  '3343197133_9256848fa9.jpg,a cyclist is performing a jumping stunt in front of a city skyline .\\n'\n",
      "  '3343197133_9256848fa9.jpg,A man is in the air on his bicycle .\\n'\n",
      "  '3343197133_9256848fa9.jpg,\"A person doing a bicycle jump , a skyline in the background .\"\\n']\n",
      " ['2353088412_5e5804c6f5.jpg,A black dog running with a stuffed bird in its mouth and another dog chasing it .\\n'\n",
      "  '2353088412_5e5804c6f5.jpg,A brown dig and black dog are playing with a stuffed toy .\\n'\n",
      "  '2353088412_5e5804c6f5.jpg,A brown dog with a toy duck in its mouth runs through snow while a black dog chases it\\n'\n",
      "  '2353088412_5e5804c6f5.jpg,Dog running with pet toy being chased by another dog .\\n'\n",
      "  '2353088412_5e5804c6f5.jpg,The brown dog is being chased by a black dog while holding a small toy in his mouth .\\n']\n",
      " ['2400958566_4e09424046.jpg,A girl hiking in front of a waterfall\\n'\n",
      "  '2400958566_4e09424046.jpg,A hiker carrying a backpack is walking past a waterfall .\\n'\n",
      "  '2400958566_4e09424046.jpg,A hiker with a backpack is walking near a waterfall .\\n'\n",
      "  '2400958566_4e09424046.jpg,A person crosses the stream in front of a waterfall .\\n'\n",
      "  '2400958566_4e09424046.jpg,A woman is backpacking through a stream in front of a waterfall .\\n']\n",
      " ...\n",
      " ['104136873_5b5d41be75.jpg,People sit on the mountainside and check out the view .\\n'\n",
      "  '104136873_5b5d41be75.jpg,Three people are on a hilltop overlooking a green valley .\\n'\n",
      "  '104136873_5b5d41be75.jpg,Three people hang out on top of a big hill .\\n'\n",
      "  '104136873_5b5d41be75.jpg,Three people overlook a green valley .\\n'\n",
      "  '104136873_5b5d41be75.jpg,Three people rest on a ledge above the moutains .\\n']\n",
      " ['374103966_2987706be1.jpg,\"A large man at a party , with a drink in his right hand .\"\\n'\n",
      "  '374103966_2987706be1.jpg,A large man in white dances in the middle of a crowd holding a beverage in his hand .\\n'\n",
      "  '374103966_2987706be1.jpg,A robust man with his mouth open in a white shirt and glasses holding a drink near other people .\\n'\n",
      "  '374103966_2987706be1.jpg,Bearded overweight man carrying drink and yawning .\\n'\n",
      "  '374103966_2987706be1.jpg,\"Overweight man with beard in white shirt holding a drink at a bar , dancing .\"\\n']\n",
      " ['3587449716_3bf1552c36.jpg,Girls in bright costumes holding little signs that say Iove you .\\n'\n",
      "  '3587449716_3bf1552c36.jpg,Three women in bright colors and headdresses are holding love message cards .\\n'\n",
      "  '3587449716_3bf1552c36.jpg,Three women in colorful costumes holding I love you signs .\\n'\n",
      "  '3587449716_3bf1552c36.jpg,\"Three women in costume are holding papers that say \"\" I love you \"\" .\"\\n'\n",
      "  '3587449716_3bf1552c36.jpg,\"Three women in elaborate costumes hold up \"\" I Love You \"\" cards .\"\\n']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(35455, 35), dtype=int64, numpy=\n",
       "array([[9661, 1061,   10, ...,    0,    0,    0],\n",
       "       [9661,   10,    6, ...,    0,    0,    0],\n",
       "       [9661,   10,  102, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [4058,   53,  162, ...,    0,    0,    0],\n",
       "       [4058,   53,  162, ...,    0,    0,    0],\n",
       "       [4058,   53,  162, ...,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sent_test)\n",
    "Y_train = text_vectorizer(flatten_sent_train)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9661, 1061,   10, ...,    0,    0,    0],\n",
       "        [9661,   10,    6, ...,    0,    0,    0],\n",
       "        [9661,   10,  102, ...,    0,    0,    0],\n",
       "        [   1,   47,    5, ...,    0,    0,    0],\n",
       "        [   1,   10,  102, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,   51,    8, ...,    0,    0,    0],\n",
       "        [6185,   28,  152, ...,    0,    0,    0],\n",
       "        [6185,   38,   12, ...,    0,    0,    0],\n",
       "        [6185,   51,   12, ...,    0,    0,    0],\n",
       "        [6185,  897,   28, ...,    0,    0,    0]],\n",
       "\n",
       "       [[3319,   10,    3, ...,    0,    0,    0],\n",
       "        [3319,   10,   74, ...,    0,    0,    0],\n",
       "        [3319,   10,   19, ...,    0,    0,    0],\n",
       "        [3319,   10,    9, ...,    0,    0,    0],\n",
       "        [3319,   44,   74, ...,    0,    0,    0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   1,  333,   11, ...,    0,    0,    0],\n",
       "        [   1, 1879,    1, ...,    0,    0,    0],\n",
       "        [8926,  508,    3, ...,    0,    0,    0],\n",
       "        [8926,   24,   84, ...,    0,    0,    0],\n",
       "        [8926,  105,  188, ...,    0,    0,    0]],\n",
       "\n",
       "       [[5225,   23,    8, ...,    0,    0,    0],\n",
       "        [5225,    8, 1040, ...,    0,    0,    0],\n",
       "        [5225,    8,    6, ...,    0,    0,    0],\n",
       "        [5225,  158,    8, ...,    0,    0,    0],\n",
       "        [   1,    8,   71, ...,    0,    0,    0]],\n",
       "\n",
       "       [[4058,   53,  138, ...,    0,    0,    0],\n",
       "        [4058,   53,  162, ...,    0,    0,    0],\n",
       "        [4058,   53,  162, ...,    0,    0,    0],\n",
       "        [4058,   53,  162, ...,    0,    0,    0],\n",
       "        [4058,   53,  162, ...,    0,    0,    0]]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(Y_train,(l_train,5,35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   1,  310,  395, ...,    0,    0,    0],\n",
       "        [   1,   15,   19, ...,    0,    0,    0],\n",
       "        [   1,  625,    6, ...,    0,    0,    0],\n",
       "        [   1,   10,    6, ...,    0,    0,    0],\n",
       "        [   1,   44,  134, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,   13,    8, ...,    0,    0,    0],\n",
       "        [   1,   23,    1, ...,    0,    0,    0],\n",
       "        [   1,   23,    8, ...,    0,    0,    0],\n",
       "        [   1,   29,    9, ...,    0,    0,    0],\n",
       "        [   1,   23,    8, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,   16,  632, ...,    0,    0,    0],\n",
       "        [   1,  586,  136, ...,    0,    0,    0],\n",
       "        [   1,  586,    9, ...,    0,    0,    0],\n",
       "        [   1,   44, 1099, ...,    0,    0,    0],\n",
       "        [   1,   17,    6, ...,    0,    0,    0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   1,  163,    5, ...,    0,    0,    0],\n",
       "        [   1,   24,   14, ...,    0,    0,    0],\n",
       "        [   1,   24, 1014, ...,    0,    0,    0],\n",
       "        [   1,   24, 4746, ...,    0,    0,    0],\n",
       "        [   1,   24, 1264, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,   55,   10, ...,    0,    0,    0],\n",
       "        [   1,   55,   10, ...,    0,    0,    0],\n",
       "        [   1,    1,   10, ...,    0,    0,    0],\n",
       "        [   1, 7552,   10, ...,    0,    0,    0],\n",
       "        [   1,   10,    9, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,    3,  350, ...,    0,    0,    0],\n",
       "        [   1,   98,    3, ...,    0,    0,    0],\n",
       "        [   1,   98,    3, ...,    0,    0,    0],\n",
       "        [   1,   98,    3, ...,    0,    0,    0],\n",
       "        [   1,   98,    3, ...,    0,    0,    0]]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_sent_test = sent_test.flatten()\n",
    "l_test = sent_test.shape[0]\n",
    "Y_test = text_vectorizer(flatten_sent_test)\n",
    "np.reshape(Y_test,(l_test,5,35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape to a Tensor: (None, 14, 14, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-dfad02bd0aa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Reshape( (-1, nb_filters))(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[1;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    353\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    356\u001b[0m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0;32m    357\u001b[0m   \u001b[0ms_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (None, 14, 14, 512)"
     ]
    }
   ],
   "source": [
    "x_input = VGG19(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "x = x_input.layers[-3].output\n",
    "shape = x.shape\n",
    "shape = tf.convert_to_tensor(shape)\n",
    "print(shape)\n",
    "# Reshape( (-1, nb_filters))(X)\n",
    "# x3d = tf.reshape( x,(-1, shape[3] ) )\n",
    "x3d = tf.reshape( x, [shape[0], shape[1] * shape[2], shape[3] ] )\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.MaxPooling2D()(x)\n",
    "print(x3d.shape)\n",
    "x3d = tf.keras.layers.Dense(256, activation=\"relu\")(x3d)\n",
    "x3d = tf.keras.layers.Dropout(rate=0.3)(x3d)\n",
    "x3d = tf.keras.layers.LSTM(512, dropout=0.3, return_sequences=True)(x3d)\n",
    "x3d = tf.keras.layers.Dense(512, activation=\"relu\")(x3d)\n",
    "x3d = tf.keras.layers.Dropout(rate=0.3)(x3d)\n",
    "x3d = tf.keras.Dropout(rate=0.3)(x3d)\n",
    "y = tf.keras.Dense(175, activation=\"softmax\")(x)\n",
    "np.reshape(y,(5,35))\n",
    "model = Model(inputs = [x_input], outputs = y)\n",
    "model.compile(loss='mean_squared_error', optimizer='RMSProp', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train, Y_train, epochs=8, batch_size=64)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
